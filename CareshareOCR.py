# -*- coding: utf-8 -*-
"""CareShareChatbot2(2).ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dY0Q0x2nSHfSrPFKUy8Ejx1TIiyqMtro
"""

!pip install torch transformers pillow

from huggingface_hub import login

login("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")

image_path = "/content/prescription.jpg"  # If the image is in the current directory

from google.colab import files

# Upload image
uploaded = files.upload()

# Extract the filename
image_path = list(uploaded.keys())[0]

image_path = "/content/images/prescription.jpg"

from transformers import BlipProcessor, BlipForConditionalGeneration
from PIL import Image
from google.colab import files

# Upload the image file
uploaded = files.upload()
image_path = list(uploaded.keys())[0]

# Load BLIP model and processor
model_name = "Salesforce/blip-image-captioning-base"
processor = BlipProcessor.from_pretrained(model_name)
model = BlipForConditionalGeneration.from_pretrained(model_name)

# Load and preprocess the image
raw_image = Image.open(image_path).convert("RGB")

# Prepare input
inputs = processor(raw_image, "Extract details from the prescription.", return_tensors="pt")

# Generate output
output = model.generate(**inputs)
print("Extracted Text:", processor.decode(output[0], skip_special_tokens=True))

import re

def extract_prescription_details(text):
    # Example patterns (adjust based on your output)
    patient_name = re.search(r"Patient Name: ([\w\s]+)", text)
    doctor_name = re.search(r"Doctor: ([\w\s]+)", text)
    medicines = re.findall(r"Medicine: ([\w\s]+) - Dosage: ([\w\d\s]+)", text)

    # Extract data if found
    details = {
        "Patient Name": patient_name.group(1) if patient_name else "Not found",
        "Doctor Name": doctor_name.group(1) if doctor_name else "Not found",
        "Medicines": medicines if medicines else "Not found"
    }
    return details

# Example Usage
output_text = "Patient Name: John Doe. Doctor: Dr. Smith. Medicine: Paracetamol - Dosage: 500mg twice daily."
details = extract_prescription_details(output_text)
print(details)

{
    "Patient Name": "John Doe",
    "Doctor Name": "Dr. Smith",
    "Medicines": [("Paracetamol", "500mg twice daily")]
}

pip install gradio

from PIL import ImageEnhance

# Enhance image quality
def enhance_image(image_path):
    image = Image.open(image_path).convert("RGB")
    enhancer = ImageEnhance.Contrast(image)
    enhanced_image = enhancer.enhance(2.0)  # Increase contrast
    return enhanced_image

!pip install pytesseract

!apt-get update
!apt-get install -y tesseract-ocr

import pytesseract
print(pytesseract.get_tesseract_version())  # This should print the Tesseract version

from google.colab import files
uploaded = files.upload()

image_path = "prescription.jpg"  # Replace with your actual uploaded file name

import gradio as gr
import pytesseract
from PIL import Image

# Function to extract text using Tesseract
def process_prescription_with_ocr(image):
    # Open the image
    extracted_text = pytesseract.image_to_string(image)

    return {"Extracted Text": extracted_text}

# Create Gradio interface
interface = gr.Interface(
    fn=process_prescription_with_ocr,
    inputs=gr.Image(type="pil"),  # Allowing users to upload images
    outputs="json",  # Return JSON with extracted text
    title="Medical Prescription OCR",
    description="Upload a prescription image, and the model will extract the text from the prescription."
)

# Launch the interface
interface.launch()

